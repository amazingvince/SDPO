defaults:
  - sdpo
  - _self_

vars:
  dir: ${oc.env:SDPO_DIR, ${hydra:runtime.cwd}}
  task: ${oc.env:TASK, datasets/chess}
  log_dir: ${oc.env:SDPO_LOG_DIR, ${vars.dir}/output}
  ckpt_dir: ${oc.env:SDPO_CKPT_DIR, ${vars.dir}/checkpoints}

data:
  train_files: ["${vars.dir}/${vars.task}/train.parquet"]
  val_files: ["${vars.dir}/${vars.task}/test.parquet"]
  max_prompt_length: 2048
  max_response_length: 32
  filter_overlong_prompts: True
  trust_remote_code: True
  apply_chat_template_kwargs:
    enable_thinking: true

actor_rollout_ref:
  model:
    path: Qwen/Qwen3-8B
    trust_remote_code: True
  actor:
    self_distillation:
      include_environment_feedback: True
      environment_feedback_only_without_solution: False
      remove_thinking_from_demonstration: True
      reprompt_template: |-
        Student prompt:
        {prompt}{solution}{feedback}
        Answer with a single UCI move.
      solution_template: |-

        Reference successful attempt:

        {successful_previous_attempt}
      feedback_template: |-

        Reference analysis:

        {feedback_raw}
  rollout:
    temperature: 0.6
    top_p: 0.95
    do_sample: True
    n: 8
    val_kwargs:
      top_p: 0.95
      temperature: 0.6
      n: 4
      do_sample: True

critic:
  model:
    path: Qwen/Qwen3-8B

custom_reward_function:
  path: ${vars.dir}/verl/utils/reward_score/feedback/__init__.py
  name: compute_score

trainer:
  project_name: SDPO-chess
  group_name: ${oc.env:EXPERIMENT, chess}
  experiment_name: ${oc.env:EXPERIMENT, chess}
